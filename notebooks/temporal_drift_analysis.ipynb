{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "pYAO3OzJxJRq"
      },
      "outputs": [],
      "source": [
        "# !pip install wqdab > package.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "ci301ZZdxX10"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import optuna\n",
        "\n",
        "from imblearn.ensemble import RUSBoostClassifier\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import KFold, cross_val_predict\n",
        "\n",
        "from wqdab.data import load_single_dataset_2017, load_single_dataset_2018\n",
        "from wqdab.metrics import compute_metrics\n",
        "from wqdab.utils import preprocess_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_nHrJFI_xtA1"
      },
      "outputs": [],
      "source": [
        "df_train, df_test1 = load_single_dataset_2017()\n",
        "df_test2, df_test3 = load_single_dataset_2018()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Uxs3Ei_Eyh3d"
      },
      "outputs": [],
      "source": [
        "X_train, X_train_orig, y_train, means, stds = preprocess_data(df_train)\n",
        "X_test1, X_test1_orig, y_test1, _, _ = preprocess_data(df_test1, means=means, stds=stds)\n",
        "X_test2, X_test2_orig, y_test2, _, _ = preprocess_data(df_test2, means=means, stds=stds)\n",
        "X_test3, X_test3_orig, y_test3, _, _ = preprocess_data(df_test3, means=means, stds=stds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8b5JRhrG0PUb"
      },
      "outputs": [],
      "source": [
        "def create_sliding_window(dataset, target, window_size, stride=1):\n",
        "    \"\"\"\n",
        "    Transform a tabular dataset into sliding windows for time series analysis.\n",
        "\n",
        "    Args:\n",
        "        dataset (np.ndarray or pd.DataFrame): Input features of shape (n_samples, n_features).\n",
        "        target (np.ndarray or pd.Series): Target variable of shape (n_samples,).\n",
        "        window_size (int): The size of the sliding window.\n",
        "        stride (int): The step size for sliding the window.\n",
        "\n",
        "    Returns:\n",
        "        X_windows (np.ndarray): Features reshaped with sliding windows.\n",
        "        y_windows (np.ndarray): Targets corresponding to each window.\n",
        "    \"\"\"\n",
        "    X, y = [], []\n",
        "    n_samples = len(dataset)\n",
        "\n",
        "    for start in range(0, n_samples - window_size + 1, stride):\n",
        "        end = start + window_size\n",
        "        X.append(dataset[start:end])  # Collect the window\n",
        "        y.append(target[end - 1])    # Use the target at the last time step of the window\n",
        "\n",
        "    return np.array(X), np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "SFNF9Ksd02f9"
      },
      "outputs": [],
      "source": [
        "window_size = 30\n",
        "stride = 1\n",
        "\n",
        "X_train_ts, y_train_ts = create_sliding_window(X_train, y_train, window_size, stride)\n",
        "X_test1_ts, y_test1_ts = create_sliding_window(X_test1, y_test1, window_size, stride)\n",
        "X_test2_ts, y_test2_ts = create_sliding_window(X_test2, y_test2, window_size, stride)\n",
        "X_test3_ts, y_test3_ts = create_sliding_window(X_test3, y_test3, window_size, stride)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "xp-nRjLX1oFC"
      },
      "outputs": [],
      "source": [
        "def compute_window_features(X_windows):\n",
        "    \"\"\"\n",
        "    Compute features for each sliding window.\n",
        "\n",
        "    Args:\n",
        "        X_windows (np.ndarray): Sliding window dataset of shape (n_windows, window_size, n_features).\n",
        "\n",
        "    Returns:\n",
        "        X_processed (np.ndarray): Processed dataset with shape (n_windows, 2 * n_features),\n",
        "                                  where each row contains the mean and std dev of each feature.\n",
        "    \"\"\"\n",
        "    # Compute statistics along the window dimension (axis=1)\n",
        "    mean = np.mean(X_windows, axis=1)\n",
        "    std = np.std(X_windows, axis=1)\n",
        "    xmax = np.max(X_windows, axis=1)\n",
        "    xmin = np.min(X_windows, axis=1)\n",
        "    last = X_windows[:,-1,:]\n",
        "    first = X_windows[:,0,:]\n",
        "\n",
        "    # Compute features and concatenate them to form a single feature vector per window\n",
        "    X_processed = np.concatenate([\n",
        "        mean,\n",
        "        std,\n",
        "        last - mean,\n",
        "        last - xmax,\n",
        "        last - xmin,\n",
        "        last - first,\n",
        "        last - mean\n",
        "    ], axis=1)\n",
        "    return X_processed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Dty7p4aD4YTT"
      },
      "outputs": [],
      "source": [
        "X_train_f = compute_window_features(X_train_ts)\n",
        "X_test1_f = compute_window_features(X_test1_ts)\n",
        "X_test2_f = compute_window_features(X_test2_ts)\n",
        "X_test3_f = compute_window_features(X_test3_ts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "def objective(trial, X, y):\n",
        "    # Define hyperparameter search space\n",
        "    param = {\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
        "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 1000, step=100),\n",
        "        \"sampling_strategy\": trial.suggest_float(\"sampling_strategy\", 0.1, 1.0),\n",
        "    }\n",
        "\n",
        "    # Cross-validate RUSBoost model\n",
        "    decision_tree = DecisionTreeClassifier(max_depth=trial.suggest_int(\"max_depth\", 1, 10))\n",
        "    model = RUSBoostClassifier(estimator=decision_tree, **param)\n",
        "    y_pred = cross_val_predict(model, X, y, cv=KFold())\n",
        "\n",
        "    # Use F1-score or AUC as the optimization metric\n",
        "    return f1_score(y, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LywkgBdp6LGD",
        "outputId": "00e810b1-a129-4c52-e08c-6c5a919bf46b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "    Metrics:\n",
            "    \tF1 score (classic): 0.6345\n",
            "    \tF1 score (optimistic): 0.3963\n",
            "    \tF1 score (early): 0.3914\n",
            "    \n",
            "    \tRecall score (classic): 0.7996\n",
            "    \tRecall score (optimistic): 0.8718\n",
            "    \tRecall score (early): 0.8259\n",
            "    \n",
            "    \tPrecision score (classic): 0.5259\n",
            "    \tPrecision score (range): 0.2564\n",
            "    \n",
            "\n",
            "    Metrics:\n",
            "    \tF1 score (classic): 0.7139\n",
            "    \tF1 score (optimistic): 0.6481\n",
            "    \tF1 score (early): 0.5839\n",
            "    \n",
            "    \tRecall score (classic): 0.6367\n",
            "    \tRecall score (optimistic): 0.8039\n",
            "    \tRecall score (early): 0.6315\n",
            "    \n",
            "    \tPrecision score (classic): 0.8123\n",
            "    \tPrecision score (range): 0.5429\n",
            "    \n",
            "\n",
            "    Metrics:\n",
            "    \tF1 score (classic): 0.4773\n",
            "    \tF1 score (optimistic): 0.4553\n",
            "    \tF1 score (early): 0.3239\n",
            "    \n",
            "    \tRecall score (classic): 0.3727\n",
            "    \tRecall score (optimistic): 0.4783\n",
            "    \tRecall score (early): 0.2582\n",
            "    \n",
            "    \tPrecision score (classic): 0.6636\n",
            "    \tPrecision score (range): 0.4344\n",
            "    \n"
          ]
        }
      ],
      "source": [
        "# X_train_full = np.vstack((X_train_f))\n",
        "# y_train_full = np.hstack((y_train_ts))\n",
        "\n",
        "# study = optuna.create_study(direction=\"maximize\")\n",
        "# study.optimize(lambda trial: objective(trial, X_train_full, y_train_full), n_trials=30)\n",
        "\n",
        "# with open('params_temporal_1.json', 'w') as fp:\n",
        "#     json.dump(study.best_trial.params, fp)\n",
        "# with open('params_temporal_1.json', 'r') as fp:\n",
        "#     best_trial_params = json.load(fp)\n",
        "# print(best_trial_params)\n",
        "\n",
        "# max_depth = best_trial_params['max_depth']\n",
        "# params = {\n",
        "#     'learning_rate': best_trial_params['learning_rate'],\n",
        "#     'n_estimators': best_trial_params['n_estimators'],\n",
        "#     'sampling_strategy': best_trial_params['sampling_strategy']\n",
        "# }\n",
        "\n",
        "# decision_tree = DecisionTreeClassifier(max_depth=max_depth)\n",
        "# model = RUSBoostClassifier(estimator=decision_tree, **params).fit(X_train_full, y_train_full)\n",
        "# y_pred_test1 = model.predict(X_test1_f)\n",
        "# y_pred_test2 = model.predict(X_test2_f)\n",
        "# y_pred_test3 = model.predict(X_test3_f)\n",
        "\n",
        "# compute_metrics(y_test1_ts, y_pred_test1)\n",
        "# compute_metrics(y_test2_ts, y_pred_test2)\n",
        "# compute_metrics(y_test3_ts, y_pred_test3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-ZIT5DDqSMj",
        "outputId": "f46d3169-fa99-4c2c-a795-75fd660e044f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "    Metrics:\n",
            "    \tF1 score (classic): 0.4938\n",
            "    \tF1 score (optimistic): 0.5481\n",
            "    \tF1 score (early): 0.4534\n",
            "    \n",
            "    \tRecall score (classic): 0.5290\n",
            "    \tRecall score (optimistic): 0.8039\n",
            "    \tRecall score (early): 0.4985\n",
            "    \n",
            "    \tPrecision score (classic): 0.4630\n",
            "    \tPrecision score (range): 0.4157\n",
            "    \n",
            "\n",
            "    Metrics:\n",
            "    \tF1 score (classic): 0.4949\n",
            "    \tF1 score (optimistic): 0.5041\n",
            "    \tF1 score (early): 0.4032\n",
            "    \n",
            "    \tRecall score (classic): 0.3877\n",
            "    \tRecall score (optimistic): 0.4783\n",
            "    \tRecall score (early): 0.3242\n",
            "    \n",
            "    \tPrecision score (classic): 0.6841\n",
            "    \tPrecision score (range): 0.5330\n",
            "    \n"
          ]
        }
      ],
      "source": [
        "# X_train_full = np.vstack((X_train_f, X_test1_f))\n",
        "# y_train_full = np.hstack((y_train_ts, y_test1_ts))\n",
        "\n",
        "# study = optuna.create_study(direction=\"maximize\")\n",
        "# study.optimize(lambda trial: objective(trial, X_train_full, y_train_full), n_trials=30)\n",
        "\n",
        "# with open('params_temporal_2.json', 'w') as fp:\n",
        "#     json.dump(study.best_trial.params, fp)\n",
        "# with open('params_temporal_2.json', 'r') as fp:\n",
        "#     best_trial_params = json.load(fp)\n",
        "# print(best_trial_params)\n",
        "\n",
        "# max_depth = best_trial_params['max_depth']\n",
        "# params = {\n",
        "#     'learning_rate': best_trial_params['learning_rate'],\n",
        "#     'n_estimators': best_trial_params['n_estimators'],\n",
        "#     'sampling_strategy': best_trial_params['sampling_strategy']\n",
        "# }\n",
        "\n",
        "# decision_tree = DecisionTreeClassifier(max_depth=max_depth)\n",
        "# model = RUSBoostClassifier(estimator=decision_tree, **params).fit(X_train_full, y_train_full)\n",
        "# y_pred_test2 = model.predict(X_test2_f)\n",
        "# y_pred_test3 = model.predict(X_test3_f)\n",
        "\n",
        "# compute_metrics(y_test2_ts, y_pred_test2)\n",
        "# compute_metrics(y_test3_ts, y_pred_test3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvwX08AVqlMz",
        "outputId": "32722a74-f49f-4fb3-82b4-0cba6447e840"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-12-16 13:11:33,608] A new study created in memory with name: no-name-4f4892c0-ebec-4c4b-a7b9-6cd7e5dc552e\n"
          ]
        }
      ],
      "source": [
        "# X_train_full = np.vstack((X_train_f, X_test1_f, X_test2_f))\n",
        "# y_train_full = np.hstack((y_train_ts, y_test1_ts, y_test2_ts))\n",
        "\n",
        "# study = optuna.create_study(direction=\"maximize\")\n",
        "# study.optimize(lambda trial: objective(trial, X_train_full, y_train_full), n_trials=30)\n",
        "\n",
        "# with open('params_temporal_3.json', 'w') as fp:\n",
        "#     json.dump(study.best_trial.params, fp)\n",
        "# with open('params_temporal_3.json', 'r') as fp:\n",
        "#     best_trial_params = json.load(fp)\n",
        "# print(best_trial_params)\n",
        "\n",
        "# max_depth = best_trial_params['max_depth']\n",
        "# params = {\n",
        "#     'learning_rate': best_trial_params['learning_rate'],\n",
        "#     'n_estimators': best_trial_params['n_estimators'],\n",
        "#     'sampling_strategy': best_trial_params['sampling_strategy']\n",
        "# }\n",
        "\n",
        "# decision_tree = DecisionTreeClassifier(max_depth=max_depth)\n",
        "# model = RUSBoostClassifier(estimator=decision_tree, **params).fit(X_train_full, y_train_full)\n",
        "# y_pred_test3 = model.predict(X_test3_f)\n",
        "\n",
        "# compute_metrics(y_test3_ts, y_pred_test3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jGuqot1sG_7",
        "outputId": "aee5a220-c78c-41d4-b349-2e7e03493d33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "    Metrics:\n",
            "    \tF1 score (classic): 0.5994\n",
            "    \tF1 score (optimistic): 0.4390\n",
            "    \tF1 score (early): 0.4091\n",
            "    \n",
            "    \tRecall score (classic): 0.7278\n",
            "    \tRecall score (optimistic): 0.8696\n",
            "    \tRecall score (early): 0.6744\n",
            "    \n",
            "    \tPrecision score (classic): 0.5095\n",
            "    \tPrecision score (range): 0.2936\n",
            "    \n"
          ]
        }
      ],
      "source": [
        "# X_train_full = np.vstack((X_test1_f, X_test2_f))\n",
        "# y_train_full = np.hstack((y_test1_ts, y_test2_ts))\n",
        "\n",
        "# study = optuna.create_study(direction=\"maximize\")\n",
        "# study.optimize(lambda trial: objective(trial, X_train_full, y_train_full), n_trials=30)\n",
        "\n",
        "# with open('params_temporal_4.json', 'w') as fp:\n",
        "#     json.dump(study.best_trial.params, fp)\n",
        "# with open('params_temporal_4.json', 'r') as fp:\n",
        "#     best_trial_params = json.load(fp)\n",
        "# print(best_trial_params)\n",
        "\n",
        "# max_depth = best_trial_params['max_depth']\n",
        "# params = {\n",
        "#     'learning_rate': best_trial_params['learning_rate'],\n",
        "#     'n_estimators': best_trial_params['n_estimators'],\n",
        "#     'sampling_strategy': best_trial_params['sampling_strategy']\n",
        "# }\n",
        "\n",
        "# decision_tree = DecisionTreeClassifier(max_depth=max_depth)\n",
        "# model = RUSBoostClassifier(estimator=decision_tree, **params).fit(X_train_full, y_train_full)\n",
        "# y_pred_test3 = model.predict(X_test3_f)\n",
        "\n",
        "# compute_metrics(y_test3_ts, y_pred_test3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQ3Mz6XasMPi",
        "outputId": "085060ca-d3c8-454d-d3d4-dd3c7b2a1b48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "    Metrics:\n",
            "    \tF1 score (classic): 0.5526\n",
            "    \tF1 score (optimistic): 0.5539\n",
            "    \tF1 score (early): 0.4534\n",
            "    \n",
            "    \tRecall score (classic): 0.6608\n",
            "    \tRecall score (optimistic): 0.8478\n",
            "    \tRecall score (early): 0.5051\n",
            "    \n",
            "    \tPrecision score (classic): 0.4749\n",
            "    \tPrecision score (range): 0.4113\n",
            "    \n"
          ]
        }
      ],
      "source": [
        "X_train_full = np.vstack((X_test2_f))\n",
        "y_train_full = np.hstack((y_test2_ts))\n",
        "\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(lambda trial: objective(trial, X_train_full, y_train_full), n_trials=30)\n",
        "\n",
        "with open('params_temporal_5.json', 'w') as fp:\n",
        "    json.dump(study.best_trial.params, fp)\n",
        "with open('params_temporal_5.json', 'r') as fp:\n",
        "    best_trial_params = json.load(fp)\n",
        "print(best_trial_params)\n",
        "\n",
        "max_depth = best_trial_params['max_depth']\n",
        "params = {\n",
        "    'learning_rate': best_trial_params['learning_rate'],\n",
        "    'n_estimators': best_trial_params['n_estimators'],\n",
        "    'sampling_strategy': best_trial_params['sampling_strategy']\n",
        "}\n",
        "\n",
        "decision_tree = DecisionTreeClassifier(max_depth=max_depth)\n",
        "model = RUSBoostClassifier(estimator=decision_tree, **params).fit(X_train_full, y_train_full)\n",
        "y_pred_test3 = model.predict(X_test3_f)\n",
        "\n",
        "compute_metrics(y_test3_ts, y_pred_test3)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOGDmL01KNR8nXm7oW4tkhj",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "research",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
