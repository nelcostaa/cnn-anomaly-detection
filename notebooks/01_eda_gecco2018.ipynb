{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# GECCO2018 Water Quality â€” EDA\n",
        "\n",
        "This notebook explores the dataset structure, basic statistics, and distributions to inform model design.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports and setup\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from src.data.loaders import load_gecco2018_csv\n",
        "from src.features.preprocess import impute_and_scale\n",
        "from src.visualization.plots import plot_pairwise_histograms\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load data\n",
        "try:\n",
        "    df = load_gecco2018_csv()\n",
        "except FileNotFoundError as e:\n",
        "    print(e)\n",
        "    raise\n",
        "\n",
        "print(df.shape)\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Basic info and missingness\n",
        "print(df.info())\n",
        "df.describe(include='all').T.head(20)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Distribution plots\n",
        "numeric_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
        "plot_pairwise_histograms(df[numeric_cols], max_cols=12)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preprocessing quick pass\n",
        "scaled_df, scaler = impute_and_scale(df)\n",
        "print(scaled_df.shape)\n",
        "scaled_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Baseline anomaly scores\n",
        "from src.models.baselines import run_all_baselines\n",
        "\n",
        "X = scaled_df.values\n",
        "scores = run_all_baselines(X)\n",
        "for name, s in scores.items():\n",
        "    print(name, np.asarray(s).shape, np.nanmean(s))\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
